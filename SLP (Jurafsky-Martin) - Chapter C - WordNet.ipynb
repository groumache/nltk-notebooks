{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "https://web.stanford.edu/~jurafsky/slp3/C.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C.1. Collect a small corpus of example sentences of varying lengths from any\n",
    "newspaper or magazine. Using WordNet or any standard dictionary, determine how many senses there are for each of the open-class words in each sentence. How many distinct combinations of senses are there for each sentence?\n",
    "How does this number seem to vary with sentence length?\n",
    "\n",
    "> But even in places where the virus is under control, schools lack the means to safely provide full-time instruction. In New York City, the nation’s largest school district says that it can only safely provide a few days each week of in-person instruction.\n",
    "https://www.nytimes.com/2020/07/10/opinion/coronavirus-schools-reopening.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 1st sentence: 21\n",
      "length 2nd sentence: 28\n",
      "combinations for the 1st sentence: 286289203200\n",
      "combinations for the 2nd sentence: 18927077621760\n",
      "1st sentence, combination/length: 2468010372\n",
      "2nd sentence, combination/length: 137152736389\n"
     ]
    }
   ],
   "source": [
    "sentence_1 = \"But even in places where the virus is under control, schools lack the means to safely provide full-time instruction.\"\n",
    "sentence_2 = \"In New York City, the nation’s largest school district says that it can only safely provide a few days each week of in-person instruction.\"\n",
    "\n",
    "words_1 = [word for word in nltk.tokenize.word_tokenize(sentence_1) if len(wn.synsets(word)) != 0]\n",
    "words_2 = [word for word in nltk.tokenize.word_tokenize(sentence_2) if len(wn.synsets(word)) != 0]\n",
    "\n",
    "nb_senses_1 = [len(wn.synsets(word)) for word in words_1]\n",
    "nb_senses_2 = [len(wn.synsets(word)) for word in words_2]\n",
    "\n",
    "combinations_1 = reduce(lambda a,b: a*b, nb_senses_1)\n",
    "combinations_2 = reduce(lambda a,b: a*b, nb_senses_2)\n",
    "\n",
    "print(\"length 1st sentence:\", len(nltk.tokenize.word_tokenize(sentence_1)))\n",
    "print(\"length 2nd sentence:\", len(nltk.tokenize.word_tokenize(sentence_2)))\n",
    "print(\"combinations for the 1st sentence:\", combinations_1)\n",
    "print(\"combinations for the 2nd sentence:\", combinations_2)\n",
    "print(\"1st sentence, combination/length:\", int(combinations_1/len(sentence_1)))\n",
    "print(\"2nd sentence, combination/length:\", int(combinations_2/len(sentence_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C.2. Using WordNet or a standard reference dictionary, tag each open-class word\n",
    "in your corpus with its correct tag. Was choosing the correct sense always a\n",
    "straightforward task? Report on any difficulties you encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter words that have only 1 sense\n",
    "\n",
    "words_1 = [word for word in words_1 if len(wn.synsets(word)) > 1]\n",
    "words_2 = [word for word in words_2 if len(wn.synsets(word)) > 1]\n",
    "\n",
    "senses_1 = [wn.synsets(word) for word in words_1]\n",
    "senses_2 = [wn.synsets(word) for word in words_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sentence 1\n",
    "\n",
    "- even$^{11}$\n",
    "- in -> not a noun/verb/adjective/adverb\n",
    "- place$^4$\n",
    "\n",
    "- virus$^1$\n",
    "- is$^1$\n",
    "- under$^4$\n",
    "\n",
    "- control$^1$\n",
    "- schools$^1$\n",
    "- lack$^1$\n",
    "\n",
    "- means$^2$\n",
    "- provide$^2$\n",
    "- full-time$^1$\n",
    "\n",
    "- instruction$^3$\n",
    "\n",
    "--------------------------\n",
    "\n",
    "#### sentence 2\n",
    "\n",
    "- In -> not a noun/verb/adjective/adverb\n",
    "- New -> part of New York City\n",
    "- City -> part of New York City\n",
    "\n",
    "- nation$^1$\n",
    "- s -> not a noun/verb/adjective/adverb\n",
    "- largest$^1$\n",
    "\n",
    "- school$^1$\n",
    "- district$^1$\n",
    "- says$^3$\n",
    "\n",
    "- can -> not a noun/verb/adjective/adverb\n",
    "- only$^3$\n",
    "- provide$^2$\n",
    "\n",
    "- a -> not a noun/verb/adjective/adverb\n",
    "- few$^2$\n",
    "- days$^2$\n",
    "\n",
    "- each$^1$\n",
    "- week$^2$\n",
    "- instruction$^3$\n",
    "\n",
    "--------------------------\n",
    "\n",
    "I think that the definition is not enough for me to determine the sense of the word, examples often help me (English is not my native language)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C.3. Using your favorite dictionary, simulate the original Lesk word overlap disambiguation algorithm described on page 16 on the phrase _Time flies like an arrow_. Assume that the words are to be disambiguated one at a time, from left to right, and that the results from earlier decisions are used later in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C.4. Build an implementation of your solution to the previous exercise. Using WordNet, implement the original Lesk word overlap disambiguation algorithm described on page 16 on the phrase Time flies like an arrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_shared_words(sentence, gloss)\n",
    "def compute_overlap(sentence: list, word: str, num_sense: int) -> int:\n",
    "    count = 0\n",
    "    count += len([w for w in sentence if w in wn.synsets(word)[num_sense].definition()])\n",
    "    count += len([w for w in sentence for example in wn.synsets(word)[num_sense].examples() if w in example])\n",
    "\n",
    "    return count\n",
    "\n",
    "def simplified_lesk(sentence: list, word: str) -> int:\n",
    "    wn.synsets(word)\n",
    "    overlap = [compute_overlap(sentence, word, i) for i in range(len(wn.synsets(word)))]\n",
    "    max_overlap = max(overlap)\n",
    "\n",
    "    return overlap.index(max_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Time', 1), ('flies', 13), ('like', 7), ('an', 0), ('arrow', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = nltk.tokenize.word_tokenize(\"Time flies like an arrow\")\n",
    "\n",
    "[(word, simplified_lesk(sentence, word)) for word in sentence]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
